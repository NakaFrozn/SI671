{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI 671/721 Homework 1: Itemset Mining (Total 100 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Academic Integrity Policy for Homework\n",
    "\n",
    "Unless otherwise specified in the homework, all submitted work must be your own original work. Any excerpts, statements, or phrases from the work of others must be clearly identified as a quotation, with proper citation provided. Any violation of the University‚Äôs policies on Academic and Professional Integrity may result in serious penalties, ranging from failing a homework assignment to failing the course, or even expulsion from the program. Violations of academic and professional integrity will be reported to the appropriate authorities. Consequences of academic misconduct are determined by the faculty instructor, and additional sanctions may also be imposed.\n",
    "\n",
    "**Collaboration with Classmates**\n",
    "\n",
    "* You may discuss homework problems with classmates or friends (no more than two friends), but you must disclose their names in your submission if you do so.\n",
    "* Even when you collaborate, your code and written answers must be your own. Submissions that are too similar may be flagged by automated code similarity checkers and necessitate instructors to investigate further to decide if any academic integrity violations have occurred.\n",
    "\n",
    "**Use of Large Language Models (LLMs)**\n",
    "\n",
    "* Consulting LLMs such as ChatGPT is not prohibited, but you must disclose in your submission if you used them for consulting. Consulting LLMs does not lead to any penality or reduction in your points.\n",
    "* The code and written work you submit must be your own. Do not copy and paste from an LLM or follow its output blindly.\n",
    "* LLMs can produce errors, omit important details, or misinterpret the assignment. You are fully responsible for checking your work, correcting mistakes, and ensuring your submission reflects your own understanding. If submissions are suspected to contain direct copied-and-pasted work from LLMs, instructors will investigate further to decide if any academic integrity violations have occurred.\n",
    "\n",
    "If you have any collaboration or use of LLMs to disclose, please use the Disclosure Template below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Disclosure (Edit this Markdown cell to disclose, if any)\n",
    "\n",
    "**Collaboration:** I discussed this assignment with [full name(s) of classmates or friends].\n",
    "\n",
    "**LLM Use:** I consulted [ChatGPT / other LLM] for [debugging ideas / clarification / brainstorming], but the final code and written answers are my own.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Tasks Summary\n",
    "\n",
    "For this assignment, we sampled ~10 thousand Tweets with two or more food/drink emojis. You will represent this dataset as a collection of itemsets and practice what we learned in class - mining and evaluating frequent itemsets, and calculating the similarity of itemsets. Specifically, we want ask a question \"Which food and drink emojis are frequently used together in Tweets?\" \n",
    "\n",
    "**Disclaimer:** The data are collected from the real world. As you step into the wild, things might not always be nice and clean. Although we, the instructing team, have tried our best effort to filter out Tweets containing poisonous vocabularies and links, it is still possible that you will encounter offensive contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details\n",
    "\n",
    "#### Data\n",
    "\n",
    "You have been provided with a folder - ‚Äòitemsets_data‚Äô - that contains all of the data for this assignment. This folder contains the following data files:\n",
    "- food_drink_emoji_tweets.txt\n",
    "- food_emoji_frequent_2_itemsets.csv\n",
    "\n",
    "#### Packages\n",
    "\n",
    "We recommend using the following Python packages in this assignment:\n",
    "- pandas\n",
    "- numpy\n",
    "- sklearn\n",
    "- matplotlib\n",
    "- mlxtend\n",
    "\n",
    "#### Assignment Structure\n",
    "\n",
    "This homework is divided into the following parts:\n",
    "\n",
    "- Part 1: Data Exploration\n",
    "- Part 2: The Apriori Algorithm\n",
    "- Part 3: Evaluating Frequent Itemsets\n",
    "- Part 4: Itemset Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT ALL NEEDED PACKAGES FOR ASSIGNMENT; No other pacakges are necessary\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Exploration [20 points]\n",
    "\n",
    "This part of the assignment is designed to help familiarize yourself with the dataset and basic concepts of itemset mining. The insights from this part will help guide your approach for the remainder of the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load & Transform the Twitter emoji dataset [11 points]\n",
    "a) **[3 points]** First, read in the **itemsets_data/food_drink_emoji_tweets.txt** file and create a pandas DataFrame (`tweets_df`) with the contents. You should find that every line of the data is a Tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "with open(\"./itemsets_data/food_drink_emoji_tweets.txt\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        tweets.append(line)\n",
    "\n",
    "tweets_df = pd.DataFrame(data={'tweets':tweets})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) **[3 points]** Using this DataFrame, extract the emojis that appear in each Tweet as an itemset. For this assignment, we are only interested in emojis that are food and drink. As such, you are supplied with the following code to filter to food and drink emojis:\n",
    "\n",
    "emoji_set = {'üç´', 'üç°', 'üçè', 'üçà', 'üçØ', 'ü•†', 'üç™', 'üå∞', 'ü•Ø', 'üçê', 'üåØ', 'üçß', 'ü•Æ', 'ü•ö', 'üçé', 'üçç', 'üç†', 'üç®', 'ü•£', 'üçä', 'üçò', 'üçÜ', 'ü•ì', 'üåΩ', 'ü•ê', 'üåÆ', 'üç¨', 'üçõ', 'ü•ò', 'ü•î', 'üçø', 'üçâ', 'ü•û', 'üçÑ', 'üéÇ', 'üßÄ', 'ü•©', 'üç∫', 'ü¶Ä', 'ü•¶', 'ü•≠', 'üçí', 'üç§', 'ü¶ê', 'ü•ù', 'ü•ô', 'üçñ', 'ü•ú', 'üç•', 'üç∑', 'üçæ', 'üç≤', 'üßÇ', 'ü•™', 'üçö', 'ü•¨', 'ü•ë', 'üçô', 'üçû', 'ü•É', 'ü•ó', 'üçï', 'üçî', 'ü•ï', 'üßÅ', 'üçã', 'üç∞', 'ü•´', 'üçó', 'ü•ß', 'ü•õ', 'üçÆ', 'ü•°', 'üçü', 'üçÖ', 'ü•Ç', 'üç∏', 'ü••', 'üç¢', 'üçå', 'üçù', 'üçµ', 'üçº', 'üç¶', 'üç≠', 'üçë', 'üçπ', 'üçá', 'ü•®', 'üç±', 'ü¶û', '‚òï', 'üå∂', 'üçª', 'üç≥', 'ü•í', 'üç£', 'ü•ü', 'ü•ñ', 'üç∂', 'üçú', 'üçì', 'ü¶ë', 'üç©', 'üå≠'}\n",
    "\n",
    "Using this set, extract all the food/drink emojis in each tweet and store them in a set - i.e., a numpy array that has no duplicated items. Add this as a new column (column name: `'emojis'`) to your DataFrame.\n",
    "\n",
    "Hint: The numpy.unique function is handy to remove duplicated items in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "emoji_set = {'üç´', 'üç°', 'üçè', 'üçà', 'üçØ', 'ü•†', 'üç™', 'üå∞', 'ü•Ø', 'üçê', 'üåØ', 'üçß', 'ü•Æ', 'ü•ö', 'üçé', 'üçç', 'üç†', 'üç®', 'ü•£', 'üçä', 'üçò', 'üçÜ', 'ü•ì', 'üåΩ', 'ü•ê', 'üåÆ', 'üç¨', 'üçõ', 'ü•ò', 'ü•î', 'üçø', 'üçâ', 'ü•û', 'üçÑ', 'üéÇ', 'üßÄ', 'ü•©', 'üç∫', 'ü¶Ä', 'ü•¶', 'ü•≠', 'üçí', 'üç§', 'ü¶ê', 'ü•ù', 'ü•ô', 'üçñ', 'ü•ú', 'üç•', 'üç∑', 'üçæ', 'üç≤', 'üßÇ', 'ü•™', 'üçö', 'ü•¨', 'ü•ë', 'üçô', 'üçû', 'ü•É', 'ü•ó', 'üçï', 'üçî', 'ü•ï', 'üßÅ', 'üçã', 'üç∞', 'ü•´', 'üçó', 'ü•ß', 'ü•õ', 'üçÆ', 'ü•°', 'üçü', 'üçÖ', 'ü•Ç', 'üç∏', 'ü••', 'üç¢', 'üçå', 'üçù', 'üçµ', 'üçº', 'üç¶', 'üç≠', 'üçë', 'üçπ', 'üçá', 'ü•®', 'üç±', 'ü¶û', '‚òï', 'üå∂', 'üçª', 'üç≥', 'ü•í', 'üç£', 'ü•ü', 'ü•ñ', 'üç∂', 'üçú', 'üçì', 'ü¶ë', 'üç©', 'üå≠'}\n",
    "\n",
    "# ANSWER - extract emojis \n",
    "\n",
    "def extract_emoji(text):\n",
    "    emojis = [e for e in text if e in emoji_set]\n",
    "    emojis_unique = np.unique(emojis)\n",
    "    return emojis_unique\n",
    "\n",
    "tweets_df['emojis'] = tweets_df['tweets'].apply(extract_emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) **[5 points]** Next, as we recommend utilizing the **mlxtend** package in this assignment to perform frequent itemset mining, you will need to transform the data. The mlxtend package requires that the itemsets be transformed into a matrix before being passed to its APIs, where each row represents an itemset and each column represents an item. Within this matrix, each cell encodes whether an item is in an itemset or not. We recommend the MultiLabelBinarizer function in scikit-learn to implement this transformation. Here is the documentation for the function: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html. Wrap the result into a pandas.DataFrame (`emoji_matrix`)so it is easier to view and work with. Use `.index` to align rows with the original tweets. Also, use `.classes_` as column names, which represent the unique emojis identified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## ANSWER - create matrix\n",
    "\n",
    "mlb_transformer = MultiLabelBinarizer()\n",
    "X = mlb_transformer.fit_transform(tweets_df['emojis'])\n",
    "emoji_matrix = pd.DataFrame(X, index=tweets_df.index, columns=mlb_transformer.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Exploratory Data Analysis (EDA) [9 points]\n",
    "\n",
    "Before we jump into analyzing a dataset, it is always wise to take a look at some summary statistics first. Some questions to consider:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **[3 points]** How many different emojis are used in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(emoji_matrix.columns)\n",
    "# ANSWER - how many different emojis are used in the dataset?\n",
    "\n",
    "\n",
    "# Display the result\n",
    "length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **[3 points]** (Part 1) How many emojis are used in a Tweet, on average? (Part 2) What does the distribution look like? Plot the distribution. You should display a figure in which the x-axis represents the number of emojis used in a Tweet, and the y-axis represents the number of Tweets that contain that number of emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.6302)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_length_mean = None\n",
    "# ANSWER - Part 1: how many emojis are used in a Tweet, on average?\n",
    "emoji_length_mean = emoji_matrix.sum(axis=1).mean()\n",
    "\n",
    "\n",
    "# Display the result\n",
    "emoji_length_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ANSWER - Part 2: what does the distribution look like? Plot the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(x=emoji_matrix.sum(axis=1), bins=25)\n",
    "plt.title(\"Distribution of Number of Emojis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **[3 points]** Which emojis are most popular (i.e., used most frequently) in the dataset? Please return the top 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "‚òï    589\n",
       "üå≠    193\n",
       "üåÆ    186\n",
       "üåØ     86\n",
       "üå∞     53\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_emojis = None\n",
    "# ANSWER - which emojis are most popular (i.e., used most frequently) in the dataset?\n",
    "top_5_emojis = emoji_matrix.sum().head(5)\n",
    "\n",
    "# Display the result\n",
    "top_5_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Apriori Algorithm [45 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to apply the Apriori algorithm to the emoji dataset. The documentation for the *apriori* function can be found at http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/. \n",
    "\n",
    "a) **[10 points]** Using *apriori*, create a function, `emoji_frequent_itemsets()`, to find all the frequent k-itemsets with a minimal support of 'min_support' in the emoji dataset. In other words, `k` and `min_support` should be arguments that are passed when the function is called, in addition to the matrix itself.\n",
    "\n",
    "Your function should return a Pandas DataFrame object with two columns: \n",
    "- The first one is named *'support'* and stores the support of the frequent itemsets. \n",
    "- The second column is named *'itemsets'* and stores the frequent itemset as a frozenset (the default return type of the apriori API).\n",
    "\n",
    "Make sure that you are only returning the frequent itemsets that have the specified number of emojis (k).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ANSWER - create & apply function\n",
    "def emoji_frequent_itemsets(data, min_support=0.01, k=2):\n",
    "    \n",
    "    # Generate frequent itemsets\n",
    "    frequent_itemsets = apriori(data, min_support=min_support, use_colnames=True)\n",
    "    \n",
    "    # Filter for itemsets with the specified number of emojis (k)\n",
    "    frequent_k_itemsets = frequent_itemsets[frequent_itemsets['itemsets'].apply(lambda x: len(x) == k)]\n",
    "    \n",
    "    return frequent_k_itemsets[['support', 'itemsets']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) **[5 points]** Using this function, find all frequent 3-itemsets with a min support of **0.007**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\.conda\\envs\\conda_env\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.0079</td>\n",
       "      <td>(üçâ, üçä, üçá)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.0092</td>\n",
       "      <td>(üçü, üçî, üçï)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.0070</td>\n",
       "      <td>(üç≠, üç¨, üç´)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.0117</td>\n",
       "      <td>(üçπ, üç∑, üç∏)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.0075</td>\n",
       "      <td>(üç∑, üç∫, üç∏)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.0076</td>\n",
       "      <td>(üç∑, üçª, üç∏)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.0072</td>\n",
       "      <td>(üç∑, ü•Ç, üç∏)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.0072</td>\n",
       "      <td>(üçπ, üç∑, üç∫)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.0077</td>\n",
       "      <td>(üçπ, üç∑, üçª)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.0070</td>\n",
       "      <td>(üçπ, üç∑, ü•Ç)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.0076</td>\n",
       "      <td>(üç∑, ü•Ç, üçæ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.0076</td>\n",
       "      <td>(üçπ, üç∫, üç∏)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.0075</td>\n",
       "      <td>(üçπ, üçª, üç∏)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0072</td>\n",
       "      <td>(üçπ, üçæ, üç∏)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.0079</td>\n",
       "      <td>(üçπ, ü•Ç, üç∏)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>(ü•Ç, üéÇ, üçæ)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     support   itemsets\n",
       "155   0.0079  (üçâ, üçä, üçá)\n",
       "156   0.0092  (üçü, üçî, üçï)\n",
       "157   0.0070  (üç≠, üç¨, üç´)\n",
       "158   0.0117  (üçπ, üç∑, üç∏)\n",
       "159   0.0075  (üç∑, üç∫, üç∏)\n",
       "160   0.0076  (üç∑, üçª, üç∏)\n",
       "161   0.0072  (üç∑, ü•Ç, üç∏)\n",
       "162   0.0072  (üçπ, üç∑, üç∫)\n",
       "163   0.0077  (üçπ, üç∑, üçª)\n",
       "164   0.0070  (üçπ, üç∑, ü•Ç)\n",
       "165   0.0076  (üç∑, ü•Ç, üçæ)\n",
       "166   0.0076  (üçπ, üç∫, üç∏)\n",
       "167   0.0075  (üçπ, üçª, üç∏)\n",
       "168   0.0072  (üçπ, üçæ, üç∏)\n",
       "169   0.0079  (üçπ, ü•Ç, üç∏)\n",
       "170   0.0104  (ü•Ç, üéÇ, üçæ)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "emoji_frequent_3itemsets = emoji_frequent_itemsets(emoji_matrix, min_support= 0.007, k= 3)\n",
    "\n",
    "# You can uncomment the following line to preview the result\n",
    "emoji_frequent_3itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Apriori Algorithm under the Hood [30 points]\n",
    "\n",
    "In this part of the assignment, we are going to continue our exploration in mining frequent itemsets. Specifically, we are going to examine a few key steps in the Apriori algorithm.\n",
    "\n",
    "#### 2.1.1 Candidate Generation\n",
    "\n",
    "A critical step of the Apriori algorithm is **candidate generation**. That is, candidate *(k+1)*-itemsets should be generated from frequent *k*-itemsets. In the following exercise, we want you to generate candidate 3-itemsets based on the frequent 2-itemsets.\n",
    "\n",
    "a) **[10 points]** You will need to construct a `generate_candidate_3_itemsets()` function, which takes in a list of frequent 2-itemsets and returns a list of the candidate 3-itemsets (\"candidate\" means that they may or may not be frequent). Please represent each itemset as a `set` in Python. Make sure that for each candidate 3-itemset in your returned list, at least one of its size-2 subset is a frequent 2-itemset, and your list does not contain duplicated itemsets.\n",
    "\n",
    "We have prepared the frequent 2-itemsets for you, which you can load from the file named **itemsets_data/food_emoji_frequent_2_itemsets.csv**. We will evaluate your function by feeding in the loaded 2-itemsets and examining the return value. Note that the loaded 2-itemsets are different from what you will get with the `emoji_frequent_itemsets` function you implemented in the previous part, as we have eliminated the drink-related emojis to make the exercise more trackable.\n",
    "\n",
    "You will receive full points if (1) every candidate 3-itemset in your returned list is a superset of at least one frequent 2-itemset, (2) every 3-itemset that has a frequent size-2 subset is already in your list, and (3) your list does not contain duplicated sets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER - Step 1: create function to generate candidates without pruning\n",
    "\n",
    "def generate_candidate_3_itemsets():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER - Step 2: apply function to data\n",
    "\n",
    "# load from file\n",
    "frequent_2_itemsets = []\n",
    "with open( ) as fin:\n",
    "    for line in fin:\n",
    "\n",
    "        \n",
    "# obtain the return value\n",
    "candidate_3_itemsets = generate_candidate_3_itemsets(frequent_2_itemsets)\n",
    "\n",
    "# You can uncomment the following line to preview the generated candidate itemsets.\n",
    "#candidate_3_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) **[10 points]** Note that this pruning procedure won't give us the smallest set of candidates. Therefore, we can further prune the candidate itemsets by requiring all size-2 subsets of each candidate 3-itemset to be frequent. \n",
    "\n",
    "Think about the example you've seen in the lecture. Suppose {üç∫, üçº}, {üç∫, üçã}, {üçº, üç≠}, {üçº, üçã} are all the frequent 2-itemsets. In the lecture, we said {üç∫, üçº, üçã}, {üç∫, üçº, üç≠}, {üçº, üç≠, üçã} are candidate 3-itemsets because each 3-itemset is a superset of at least one frequent 2-itemset. However, a larger itemset can never be frequent as long as one of its subset is not frequent. In this case, {üç∫, üçº, üç≠} can never been frequent because {üç∫, üç≠} is not frequent. Neither can {üçº, üç≠, üçã}, as the subset {üç≠, üçã} is not frequent. Ideally, we should be able to exclude the two candidate 3-itemsets {üç∫, üçº, üç≠} and {üçº, üç≠, üçã} even without scanning the database for counting.\n",
    "\n",
    "For this exercise, please prune your generated candidate 3-itemsets by requiring all their subsets to be frequent. You will receive full points for this part if the pruning is done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER - Step 1: create function to generate candidates with pruning\n",
    "\n",
    "def generate_candidate_3_itemsets_pruned():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ANSWER - Step 2: apply function to data\n",
    "\n",
    "# load from file\n",
    "frequent_2_itemsets = []\n",
    "with open( ) as fin:\n",
    "    for line in fin:\n",
    "\n",
    "        \n",
    "# obtain the return value\n",
    "candidate_3_itemsets_pruned = generate_candidate_3_itemsets_pruned(frequent_2_itemsets)\n",
    "\n",
    "# You can uncomment the following line to preview the generated candidate itemsets.\n",
    "#candidate_3_itemsets_pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Database Scan\n",
    "\n",
    "c) **[10 points]** With the candidate itemsets ready, the final step in one iteration of the Apriori algorithm is to scan the database (in our case, you can scan the `emoji_matrix` created above in 1.1c) and count the occurrence of each candidate itemset, divide it by the total number of records to derive the support, and output candidate itemsets whose support meets a chosen threshold.\n",
    "\n",
    "To do so, please construct a new function, `calculate_frequent_itemsets()`, where the input (`candidate_itemsets`) is a list of the candidate 3-itemsets from the previous section. Your function should return a complete list of frequent 3-itemsets with a minimal support of `min_support` (i.e., an argument passed to the function). The returned list should not contain duplicated itemsets. The order of the list does not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER - function to calculate support & return itemsets that meet the passed min_support value\n",
    "\n",
    "def calculate_frequent_itemsets(candidate_itemsets, min_support=0.005):\n",
    "    \n",
    "\n",
    "calculate_frequent_itemsets(candidate_3_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluating Frequent Itemsets [25 points]\n",
    "\n",
    "Even though you may have found all the frequent itemsets, not all of them are ‚Äúinteresting‚Äù. \n",
    "\n",
    "People have developed various measurements of the interestingness of patterns. Most of them split the itemset into an antecedent item(set) and a consequent item(set), and then measure the correlation between the antecedent and the consequent. Let's try some of such measurements implemented by the `mlxtend.frequent_patterns.association_rules` API. For more information about the API, visit the documentation at http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/.\n",
    "\n",
    "a) **[10 points]** First, apply the apriori function to `emoji_matrix` created in section 1.1c with a `min_support` of 0.005 and `use_colnames = True`. Then, apply the `association_rules` function to the result with `metric = \"lift\"` and `min_threshold = 3` (meaning to only return values where lift is equal to or greater than 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_frequent_itemsets = None\n",
    "# ANSWER - Part 1: apply apriori\n",
    "\n",
    "# Display the results\n",
    "emoji_frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interestingness_measurements = None\n",
    "# ANSWER - apply association_rules\n",
    "\n",
    "\n",
    "# You can uncommentize the line below to preview the results\n",
    "#interestingness_measurements.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) **[10 points]** Next, we ask that you implement another interestingness measurement, the (full) mutual information. The measurement is defined as such:\n",
    "\n",
    "\n",
    "The measurement is defined as:\n",
    "\n",
    "$$I(X;Y)=\\sum_{x\\in\\mathcal{X}}\\sum_{y\\in\\mathcal{Y}} P(X=x, Y=y)\\log_2\\frac{P(X=x,Y=y)}{P(X=x)P(Y=y)}.$$\n",
    "\n",
    "Note that the logarithm requires that the joint probability $P(X=x, Y=y) > 0$, which does not hold for some $(x, y)$. However, since we know that when $P(X=x, Y=y) = 0$, it would not contribute to the sum, you may assume $P(X=x, Y=y)\\log_2\\frac{P(X=x,Y=y)}{P(X=x)P(P=y)} = 0$ in that case. \n",
    "\n",
    "$x$, $y$ are possible values of $X$ and $Y$; in the case of appearance or absence of an item, 1 or 0. Therefore, we need to consider all possible combinations of $x$ and $y$, that is, $(X=1, Y=1)$, $(X=1, Y=0)$, $(X=0, Y=1)$, $(X=0, Y=0)$.\n",
    "\n",
    "Please construct a function, `mi()`,  that uses the three support values ((1) antecedent support, (2) consequent support and (3) support) to compute the mutual information. All three parameters are in [0, 1], and you can assume the validity of the input. **Use 2 as the log base.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER - create function to calculate MI\n",
    "\n",
    "def mi(antecedent_support, consequent_support, support):\n",
    "      \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) **[5 points]** Then, use this function to add the mutual information value to each row of the DataFrame (`interestingness_measurements`) above (i.e., the results of applying association_rules)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER - add MI to the dataframe and add a column ('mi') to contain the results\n",
    "interestingness_measurements['mi'] = \n",
    "\n",
    "# You can uncommentize the line below to preview the results\n",
    "#interestingness_measurements.sort_values('mi', ascending=False).head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Itemset Similarity [10 points]\n",
    "\n",
    "Recall that pattern and similarity are two basic outputs of data mining. So far, we have been playing with patterns - frequent itemsets and association rules can all be seen as \"patterns\". In the last part, let's work on itemset similarities.\n",
    "\n",
    "### 4.1 Jaccard Similarity\n",
    "\n",
    "Jaccard similarity is a simple but powerful measurement of itemset similarity, defined as follows:\n",
    "\n",
    "$$\\text{Jaccard_similarity(A, B)} = \\frac{|A\\cap B|}{|A\\cup B|}$$\n",
    "\n",
    "a) **[5 points]** Complete a function, `jaccard_similarity()`, to calculate the Jaccard similarity between two sets. You may assume that at least one of the sets is not empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER - function to calculate jaccard similarity\n",
    "def jaccard_similarity(,):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) **[5 points]** With this Jaccard similarity function, please calculate the Jaccard similarity between any given Tweet with all other Tweets and find the Tweets that are most similar (i.e., have the highest jaccard similarity values) in terms of the set of food/drink emojis used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER - apply Jaccard similarity function to Tweets and add a column ('jaccard') to contain the results\n",
    "\n",
    "tweets_df['jaccard'] =\n",
    "\n",
    "# Display the top 10 results\n",
    "tweets_df.sort_values('jaccard',ascending= ).head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "All submissions should be made to Canvas electronically by 11:59 PM EST on September 26.\n",
    "\n",
    "Here are the main deliverables:\n",
    "- A PDF version of your executed Jupyter Notebook (submitted to `Homework1 Submission - pdf` on Canvas)\n",
    "\n",
    "- The actual Jupyter notebook, so that we can check your results (submitted to `Homework 1 Submission - notebook` on Canvas)\n",
    "\n",
    "Please make sure to provide appropriate conclusions drawn from the code/results throughout the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
